{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fd922a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "After finishing the previous document -- Numpy Tutorial, I decided to devote this to demonstrating how to read **dataframes** using [pandas](https://pandas.pydata.org/docs/reference/io.html) and complete some related matrix computation on the extracted data.\n",
    "\n",
    "Our input is a text corpus from [zhihu.com](https://www.zhihu.com/question/21051140) about the grand layoff wave in China in the early 90s. My aunt and uncle were once factory workers before the layoffs. When I visited my hometown, I usually lodged in their home, listening to them recount their poignant stories during that era. Therefore, despite the generation gap, I was relatively familiar with the hardship that they have been through.  \n",
    "\n",
    "(Apology for my digression)\n",
    "\n",
    "This notebook will demonstrate playing with a file, the rows of which would stand for documents while the columns are keywords showing up in those documents. If the number in the cell is one, that word does appear in that document; zero otherwise.\n",
    "\n",
    "\n",
    "Should I have time in the future, I will explore more NLP-related topics based on this document.  \n",
    "\n",
    "**Table of Contents**:<br>\n",
    "&nbsp;&nbsp;&nbsp;1. Introduction (we are here)<br>\n",
    "&nbsp;&nbsp;&nbsp;2. Import packages<br>\n",
    "&nbsp;&nbsp;&nbsp;3. Use pandas to read in datasets from Excel<br>\n",
    "&nbsp;&nbsp;&nbsp;4. Extract Data<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.1 Slicing<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.2 Convert the dataframe into a 2-D array<br>\n",
    "&nbsp;&nbsp;&nbsp;5. Extract labels<br>\n",
    "&nbsp;&nbsp;&nbsp;6. Matrix algebra<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.1 Co-word matrix<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.2 Documents similarity<br>\n",
    "&nbsp;&nbsp;&nbsp;7. What's next?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597c100",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "To play around with the data, we will call functions from [pandas](https://pandas.pydata.org/docs/reference/io.html). Thus, we need to import pandas first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4d47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1bac5",
   "metadata": {},
   "source": [
    "# Use pandas to read in datasets from Excel\n",
    "There are a couple of [functions](https://pandas.pydata.org/docs/reference/io.html) that we could draw upon to parse files in standard formats, such as CSV, Excel, JSON, etc. Their augment lists have much in common. Here, we will practice how to read in Excel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9aeee",
   "metadata": {},
   "source": [
    "First, we use [read_excel()](https://sparkbyexamples.com/pandas/pandas-read-excel-with-examples/) to read in the specified file 'word_occurence_matrix.xlsx' that will output a Dataframe. Please make sure to denote the path if our Excel file is not under the same directory that this .ipynb is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89f3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinhua/opt/anaconda3/lib/python3.9/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('input/word_occurrence_matrix.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad92b5f",
   "metadata": {},
   "source": [
    "We can call [head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) to output the file line by line from the top. If no argument is specified, head() will output the first five rows by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a90b657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>序号</th>\n",
       "      <th>正文</th>\n",
       "      <th>企业</th>\n",
       "      <th>工人</th>\n",
       "      <th>国家</th>\n",
       "      <th>问题</th>\n",
       "      <th>经济</th>\n",
       "      <th>父母</th>\n",
       "      <th>中国</th>\n",
       "      <th>年代</th>\n",
       "      <th>...</th>\n",
       "      <th>大环境</th>\n",
       "      <th>素质</th>\n",
       "      <th>师傅</th>\n",
       "      <th>地主</th>\n",
       "      <th>道德</th>\n",
       "      <th>学会</th>\n",
       "      <th>人群</th>\n",
       "      <th>理论</th>\n",
       "      <th>主义</th>\n",
       "      <th>金融危机</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>我听我爸说当时我们这边的下岗的人    好多都找不到工作   吃不上饭 然后好多跳楼跳河的我...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>上了些年纪，所以不幸是亲历者。看了各答后，做一旁补，大下岗之前几年，也就是八十年代最末的一年...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>原因很简单经济要好国家要强大大家就要好好工作不管你怎么说事实胜于雄辩以前的体制就是极度让人懒...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>看完这个答案我才明白原来当年国企里面养了一厂的王进喜啊。各位的七大姑八大姨说自己多努力工作的...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>下岗潮的一大后果就是生产力被重创,朱执政有一年纺织品价格翻了两倍,通胀就是这么一点一滴攒起来的</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 522 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    序号                                                 正文   企业   工人   国家   问题  \\\n",
       "0  1.0  我听我爸说当时我们这边的下岗的人    好多都找不到工作   吃不上饭 然后好多跳楼跳河的我...  0.0  0.0  0.0  0.0   \n",
       "1  3.0  上了些年纪，所以不幸是亲历者。看了各答后，做一旁补，大下岗之前几年，也就是八十年代最末的一年...  0.0  0.0  1.0  1.0   \n",
       "2  4.0  原因很简单经济要好国家要强大大家就要好好工作不管你怎么说事实胜于雄辩以前的体制就是极度让人懒...  0.0  0.0  1.0  0.0   \n",
       "3  5.0  看完这个答案我才明白原来当年国企里面养了一厂的王进喜啊。各位的七大姑八大姨说自己多努力工作的...  0.0  1.0  1.0  0.0   \n",
       "4  6.0    下岗潮的一大后果就是生产力被重创,朱执政有一年纺织品价格翻了两倍,通胀就是这么一点一滴攒起来的  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    经济   父母   中国   年代  ...  大环境   素质   师傅   地主   道德   学会   人群   理论   主义  金融危机  \n",
       "0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1  1.0  0.0  0.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "4  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 522 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6150c3",
   "metadata": {},
   "source": [
    "# Extract Data\n",
    "## Slicing\n",
    "Since we've got our Dataframe from above, we will focus on slicing data to single out the data we want.\n",
    "\n",
    "As what [Selecting, Slicing and Filtering data in a Pandas DataFrame](https://www.opentechguides.com/how-to/article/pandas/193/index-slice-subset.html) mentioned：\n",
    "> One of the essential features that a data analysis tool must provide users for working with large data-sets is the ability to select, slice, and filter data easily. \n",
    "\n",
    "There are two ways of slicing -- using index or labels. Both include : operator. Then what does : do?\n",
    "\n",
    ": can be understood as a range operator, where left : right means displaying the data within the range from left to right (**inclusive** if using labels; **exclusive** if using indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e1afcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>企业</th>\n",
       "      <th>工人</th>\n",
       "      <th>国家</th>\n",
       "      <th>问题</th>\n",
       "      <th>经济</th>\n",
       "      <th>父母</th>\n",
       "      <th>中国</th>\n",
       "      <th>年代</th>\n",
       "      <th>工厂</th>\n",
       "      <th>工资</th>\n",
       "      <th>...</th>\n",
       "      <th>大环境</th>\n",
       "      <th>素质</th>\n",
       "      <th>师傅</th>\n",
       "      <th>地主</th>\n",
       "      <th>道德</th>\n",
       "      <th>学会</th>\n",
       "      <th>人群</th>\n",
       "      <th>理论</th>\n",
       "      <th>主义</th>\n",
       "      <th>金融危机</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1515 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       企业   工人   国家   问题   经济   父母   中国   年代   工厂   工资  ...  大环境   素质   师傅  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "2     0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3     0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  ...  0.0  0.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1510  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1511  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1512  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "1513  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1514  1.0  0.0  0.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  ...  0.0  1.0  0.0   \n",
       "\n",
       "       地主   道德   学会   人群   理论   主义  金融危机  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "...   ...  ...  ...  ...  ...  ...   ...  \n",
       "1510  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1511  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1512  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1513  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1514  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[1515 rows x 520 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_occurrence_matrix = df.iloc[:, 2:]\n",
    "df_word_occurrence_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcd9a3",
   "metadata": {},
   "source": [
    "## Convert the dataframe into a 2-D array\n",
    "In order to do computation with the data, we have to [convert the Dataframe into an array](https://www.geeksforgeeks.org/python-pandas-dataframe-values/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509cdfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_word_occurrence_matrix = df_word_occurrence_matrix.values\n",
    "array_word_occurrence_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35a895",
   "metadata": {},
   "source": [
    "# Extract labels\n",
    "Labels are the identities of each column. It will not hurt if we back up the labels of our data, lest it will come in handy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361d9bd",
   "metadata": {},
   "source": [
    "To collect the labels, we call [dataframe.columns](https://www.geeksforgeeks.org/python-pandas-dataframe-columns/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a854163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  520  words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['企业', '工人', '国家', '问题', '经济', '父母', '中国', '年代', '工厂', '工资',\n",
       "       ...\n",
       "       '大环境', '素质', '师傅', '地主', '道德', '学会', '人群', '理论', '主义', '金融危机'],\n",
       "      dtype='object', length=520)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_labels = df_word_occurrence_matrix.columns\n",
    "print(\"There are \", len(word_labels), \" words\")\n",
    "word_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef61ff5",
   "metadata": {},
   "source": [
    "Or, we can even display all of them as a matrix by calling [.values](https://www.geeksforgeeks.org/python-pandas-dataframe-values/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "292b1fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['企业', '工人', '国家', '问题', '经济', '父母', '中国', '年代', '工厂', '工资', '父亲',\n",
       "       '社会', '单位', '政府', '领导', '职工', '城市', '妈妈', '国有企业', '孩子', '家庭', '农民',\n",
       "       '下岗工人', '母亲', '地方', '公司', '厂子', '政策', '爸爸', '员工', '我家', '技术', '时代',\n",
       "       '市场', '大学', '关系', '原因', '经历', '时间', '结果', '农村', '东西', '下岗职工', '利益',\n",
       "       '厂里', '工龄', '厂长', '工业', '一家', '历史', '个人', '效益', '生意', '小学', '学校',\n",
       "       '收入', '同学', '感觉', '效率', '体制', '全国', '福利', '日子', '办法', '答案', '行业',\n",
       "       '房子', '强势', '能力', '爷爷', '计划经济', '铁饭碗', '人民', '公务员', '医院', '市场经济',\n",
       "       '产品', '制度', '初中', '朋友', '美国', '要求', '银行', '高中', '子弟', '社会主义', '负担',\n",
       "       '资源', '成本', '劳动力', '人员', '条件', '老板', '人们', '上海', '阿姨', '压力',\n",
       "       '资本主义', '儿子', '叔叔', '亲戚', '工人阶级', '产业', '子女', '丈夫', '世界', '九十年代',\n",
       "       '财政', '过程', '环境', '水平', '利润', '盈利', '日本', '机会', '苏联', '煤矿', '幼儿园',\n",
       "       '中央', '部门', '印象', '国有资产', '地区', '车间', '资金', '方式', '同事', '价格', '全家',\n",
       "       '一代', '人口', '岗位', '老师', '大学生', '衣服', '资本', '农业', '事业', '包袱', '人生',\n",
       "       '基础', '政治', '没人', '医疗', '北京', '家乡', '年轻人', '农民工', '私人', '干部', '程度',\n",
       "       '背景', '退休金', '工人下岗', '资产', '年纪', '女儿', '一代人', '县城', '老人', '体系',\n",
       "       '贷款', '朱镕基', '邻居', '纺织厂', '计划', '设备', '技能', '群体', '学费', '年龄', '待遇',\n",
       "       '老百姓', '角度', '危机', '身体', '系统', '投资', '办公室', '思想', '司机', '责任', '机器',\n",
       "       '老家', '命运', '家属', '事件', '姐姐', '报纸', '会计', '奶奶', '状态', '阶级', '生活费',\n",
       "       '代表', '权力', '地位', '双职工', '文化', '精神', '都会', '样子', '记忆', '人才', '生产力',\n",
       "       '住房', '集体', '现实', '意思', '公有制', '竞争力', '父辈', '小时', '世纪', '男人', '土地',\n",
       "       '评论', '现象', '说法', '钢铁', '粮食', '年级', '老妈', '概念', '资本家', '本质', '阶层',\n",
       "       '东北人', '化肥', '小区', '学生', '职业', '需求', '例子', '姥爷', '石油', '老婆', '阵痛',\n",
       "       '优势', '成都', '电视', '代价', '悲剧', '实际', '集团', '话题', '来源', '意识', '规模',\n",
       "       '状况', '外公', '饭碗', '代人', '外婆', '大人', '女人', '权利', '知识', '专业', '电话',\n",
       "       '行为', '大潮', '原本', '数据', '经验', '大锅饭', '产业工人', '运动', '官员', '我国',\n",
       "       '身份', '重工业', '错误', '事实', '宿舍', '城镇', '朱相', '目的', '铁路', '新闻', '户口',\n",
       "       '群众', '核心', '手段', '机构', '进厂', '所有人', '典型', '财富', '姥姥', '厂房', '契约',\n",
       "       '底层', '方向', '目标', '自行车', '电影', '舅舅', '方法', '沈阳', '夫妻', '精英', '学历',\n",
       "       '心理', '爷爷奶奶', '后果', '马上', '模式', '合同', '总理', '私营企业', '养老金', '基层',\n",
       "       '价值', '个体', '习惯', '姑姑', '本事', '比例', '管理层', '深圳', '支出', '超市', '性质',\n",
       "       '机械', '记者', '青春', '老公', '家人', '小孩', '形势', '股份制', '仓库', '自主权',\n",
       "       '国营企业', '中学', '贡献', '作用', '麻将', '积蓄', '项目', '因素', '主任', '后代', '观念',\n",
       "       '市里', '保险', '官僚', '院子', '差距', '大厂', '广东', '姑父', '成绩', '接班', '态度',\n",
       "       '所有制', '一生', '家长', '老张', '理由', '困境', '整体', '感情', '经理', '工程师', '低价',\n",
       "       '八十年代', '逻辑', '层面', '重点', '教师', '主人', '老工人', '朱总理', '商品', '常常',\n",
       "       '萧条', '基地', '试点', '编制', '知青', '姨夫', '存款', '名字', '决策', '措施', '一线',\n",
       "       '工种', '标准', '全民', '知识分子', '房价', '好处', '纺织', '忽悠', '勉强', '高层', '早点',\n",
       "       '看法', '力量', '心情', '思维', '想法', '百姓', '汽车', '普通人', '浪潮', '方案', '劳动者',\n",
       "       '规定', '四川', '生计', '研究生', '质量', '食堂', '女工', '任务', '费用', '民营企业',\n",
       "       '结构', '姑娘', '妹妹', '家政', '张苏玉', '手艺', '中心', '出租车', '蛀虫', '积极性',\n",
       "       '乡镇企业', '活力', '刘欢', '女性', '道理', '电影院', '遭遇', '厉害', '经济学', '棺材',\n",
       "       '兄弟', '共产主义', '偶尔', '手机', '机关', '工程', '劳模', '欺负', '鞍钢', '军工', '大爷',\n",
       "       '香港', '医生', '阶段', '闹事', '辽宁', '甩包袱', '青年', '中专', '两口子', '隔壁', '坐标',\n",
       "       '山东', '眼光', '形式', '设施', '地步', '空间', '观点', '蔬菜', '居民', '税收', '班主任',\n",
       "       '高福利', '煤炭', '数量', '亲人', '街道', '剪刀差', '制造业', '数字', '背叛', '心态',\n",
       "       '战争', '对象', '传统', '出路', '尤国英', '范围', '远远', '特色', '电脑', '外资', '俄罗斯',\n",
       "       '关键', '机遇', '利润留成', '生产线', '局面', '原材料', '消息', '临时工', '风险', '蛋糕',\n",
       "       '默默', '原料', '市长', '奖金', '大姨', '金融', '大环境', '素质', '师傅', '地主', '道德',\n",
       "       '学会', '人群', '理论', '主义', '金融危机'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf20ba3",
   "metadata": {},
   "source": [
    "# Matrix algebra\n",
    "array_word_occurrence_matrix records the occurrences of keywords in each document.\n",
    "* Every row represents one document\n",
    "* Every column represents one word\n",
    "\n",
    "Each row vector from the above matrix is the skeleton of a document, telling if a particular keyword appears in that document or not. Indeed，we can take dot product between those row vectors(two documents). We can even safely compute the cosine similarity between any two documents. If we use ${A}$ to represent array_word_occurrence_matrix, then $A{A}^T$ is the resultant matrix of the dot products taken between all row vectors (even a row vector to itself). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a01d9b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = array_word_occurrence_matrix\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "880b35d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       [0., 1., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790d5487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0., 36.,  2., ...,  3.,  3.,  5.],\n",
       "       [ 0.,  2.,  6., ...,  1.,  0.,  1.],\n",
       "       ...,\n",
       "       [ 0.,  3.,  1., ..., 13.,  4.,  2.],\n",
       "       [ 1.,  3.,  0., ...,  4., 35.,  4.],\n",
       "       [ 0.,  5.,  1., ...,  2.,  4., 28.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c585911",
   "metadata": {},
   "source": [
    "Interestingly, ${A}^T$ can be viewed as an **observation matrix** which can be used to derive sample covariance matrix $S = \\frac{1}{n - 1}{B}{B}^T$, where ${B}$ here is matrix ${A}^T$ in mean-deviation form.\n",
    "\n",
    "To take mean of the columns of ${A}^T$, we call [matrix.mean()](https://numpy.org/doc/stable/reference/generated/numpy.matrix.mean.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bda0051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24752475, 0.29834983, 0.32277228, 0.21320132, 0.19735974,\n",
       "       0.18613861, 0.14983498, 0.19405941, 0.15841584, 0.15907591,\n",
       "       0.10429043, 0.17623762, 0.12739274, 0.1379538 , 0.13333333,\n",
       "       0.10825083, 0.13267327, 0.08382838, 0.07062706, 0.11683168,\n",
       "       0.11485149, 0.0990099 , 0.11221122, 0.08184818, 0.11353135,\n",
       "       0.07788779, 0.09240924, 0.11353135, 0.07128713, 0.1009901 ,\n",
       "       0.10561056, 0.09636964, 0.11023102, 0.08910891, 0.1029703 ,\n",
       "       0.10891089, 0.10363036, 0.10693069, 0.1049505 , 0.0950495 ,\n",
       "       0.06534653, 0.09636964, 0.07656766, 0.08118812, 0.06468647,\n",
       "       0.08514851, 0.05940594, 0.05742574, 0.08250825, 0.08448845,\n",
       "       0.08250825, 0.08382838, 0.07326733, 0.08316832, 0.06864686,\n",
       "       0.0660066 , 0.07062706, 0.09174917, 0.0640264 , 0.07194719,\n",
       "       0.06336634, 0.07062706, 0.07194719, 0.06864686, 0.07326733,\n",
       "       0.0620462 , 0.06006601, 0.06270627, 0.06732673, 0.03828383,\n",
       "       0.05544554, 0.05742574, 0.05478548, 0.05742574, 0.04752475,\n",
       "       0.05016502, 0.04818482, 0.04686469, 0.05412541, 0.05412541,\n",
       "       0.03234323, 0.04950495, 0.04026403, 0.05478548, 0.04158416,\n",
       "       0.04488449, 0.04752475, 0.04224422, 0.04620462, 0.03168317,\n",
       "       0.04224422, 0.04752475, 0.04686469, 0.03630363, 0.0290429 ,\n",
       "       0.03762376, 0.04686469, 0.0330033 , 0.03630363, 0.04092409,\n",
       "       0.04884488, 0.04224422, 0.0349835 , 0.05148515, 0.01320132,\n",
       "       0.04620462, 0.04422442, 0.0290429 , 0.04818482, 0.04818482,\n",
       "       0.04554455, 0.02772277, 0.0310231 , 0.01848185, 0.04620462,\n",
       "       0.0330033 , 0.01518152, 0.03828383, 0.02574257, 0.0290429 ,\n",
       "       0.04356436, 0.04554455, 0.03036304, 0.03036304, 0.02838284,\n",
       "       0.03828383, 0.04158416, 0.02970297, 0.03762376, 0.04356436,\n",
       "       0.03234323, 0.03960396, 0.03366337, 0.02838284, 0.03036304,\n",
       "       0.0349835 , 0.02772277, 0.03762376, 0.03828383, 0.03762376,\n",
       "       0.03630363, 0.0310231 , 0.04092409, 0.03366337, 0.02640264,\n",
       "       0.0310231 , 0.03762376, 0.02310231, 0.0369637 , 0.02706271,\n",
       "       0.03960396, 0.0369637 , 0.0330033 , 0.04026403, 0.03630363,\n",
       "       0.03828383, 0.02310231, 0.03432343, 0.02310231, 0.03168317,\n",
       "       0.0349835 , 0.02574257, 0.02706271, 0.0290429 , 0.02112211,\n",
       "       0.02310231, 0.03168317, 0.0330033 , 0.02838284, 0.03234323,\n",
       "       0.03432343, 0.0330033 , 0.03366337, 0.03168317, 0.02706271,\n",
       "       0.03036304, 0.02244224, 0.02310231, 0.02310231, 0.02508251,\n",
       "       0.01914191, 0.02970297, 0.02706271, 0.02838284, 0.03168317,\n",
       "       0.02178218, 0.0310231 , 0.01584158, 0.01716172, 0.02244224,\n",
       "       0.02442244, 0.0310231 , 0.02046205, 0.01914191, 0.0290429 ,\n",
       "       0.02508251, 0.03234323, 0.03036304, 0.03036304, 0.03036304,\n",
       "       0.03366337, 0.02706271, 0.0310231 , 0.02508251, 0.01980198,\n",
       "       0.02640264, 0.0290429 , 0.0310231 , 0.02772277, 0.01716172,\n",
       "       0.02640264, 0.02838284, 0.02772277, 0.02970297, 0.02178218,\n",
       "       0.02508251, 0.02640264, 0.02244224, 0.02772277, 0.01716172,\n",
       "       0.02112211, 0.02574257, 0.01518152, 0.02640264, 0.02112211,\n",
       "       0.02706271, 0.02178218, 0.02046205, 0.00990099, 0.01914191,\n",
       "       0.02310231, 0.02574257, 0.01980198, 0.02772277, 0.01188119,\n",
       "       0.02244224, 0.02178218, 0.02376238, 0.02244224, 0.01122112,\n",
       "       0.02310231, 0.02178218, 0.02376238, 0.02376238, 0.01914191,\n",
       "       0.02838284, 0.02442244, 0.02376238, 0.02376238, 0.02046205,\n",
       "       0.01716172, 0.02046205, 0.02706271, 0.01650165, 0.02310231,\n",
       "       0.01386139, 0.01848185, 0.02112211, 0.01980198, 0.01518152,\n",
       "       0.02508251, 0.02640264, 0.02046205, 0.01914191, 0.02178218,\n",
       "       0.01914191, 0.01914191, 0.01980198, 0.01782178, 0.02046205,\n",
       "       0.01848185, 0.01980198, 0.01848185, 0.02442244, 0.01716172,\n",
       "       0.01320132, 0.00792079, 0.02112211, 0.01122112, 0.02178218,\n",
       "       0.01518152, 0.01452145, 0.01650165, 0.02244224, 0.01716172,\n",
       "       0.01716172, 0.02376238, 0.02178218, 0.02112211, 0.01122112,\n",
       "       0.02046205, 0.01782178, 0.02376238, 0.01914191, 0.01716172,\n",
       "       0.02178218, 0.01386139, 0.01452145, 0.01452145, 0.00990099,\n",
       "       0.01980198, 0.01848185, 0.01584158, 0.01980198, 0.01782178,\n",
       "       0.02178218, 0.02178218, 0.02112211, 0.01650165, 0.02178218,\n",
       "       0.01122112, 0.02046205, 0.01782178, 0.01980198, 0.01980198,\n",
       "       0.02112211, 0.01386139, 0.01848185, 0.01386139, 0.01584158,\n",
       "       0.01584158, 0.01386139, 0.01452145, 0.01716172, 0.01518152,\n",
       "       0.00726073, 0.01980198, 0.01452145, 0.01848185, 0.02046205,\n",
       "       0.01584158, 0.01386139, 0.01650165, 0.00594059, 0.01452145,\n",
       "       0.01980198, 0.02112211, 0.01716172, 0.01452145, 0.01782178,\n",
       "       0.01782178, 0.01716172, 0.01452145, 0.01452145, 0.01716172,\n",
       "       0.01848185, 0.01848185, 0.01056106, 0.01188119, 0.01320132,\n",
       "       0.01716172, 0.01254125, 0.00990099, 0.01518152, 0.01188119,\n",
       "       0.01848185, 0.01188119, 0.01914191, 0.01386139, 0.00066007,\n",
       "       0.01980198, 0.01584158, 0.01716172, 0.01782178, 0.01056106,\n",
       "       0.01518152, 0.01716172, 0.01254125, 0.01320132, 0.01386139,\n",
       "       0.01782178, 0.01056106, 0.01452145, 0.01584158, 0.01584158,\n",
       "       0.00990099, 0.01386139, 0.00990099, 0.01188119, 0.00462046,\n",
       "       0.01650165, 0.01320132, 0.00924092, 0.01188119, 0.01848185,\n",
       "       0.01320132, 0.01518152, 0.01386139, 0.01320132, 0.01716172,\n",
       "       0.01188119, 0.01386139, 0.01716172, 0.01782178, 0.01452145,\n",
       "       0.01386139, 0.01848185, 0.01584158, 0.01320132, 0.01584158,\n",
       "       0.01716172, 0.01650165, 0.01254125, 0.01716172, 0.01518152,\n",
       "       0.01254125, 0.01386139, 0.01650165, 0.01320132, 0.01188119,\n",
       "       0.01188119, 0.01188119, 0.01584158, 0.00660066, 0.01452145,\n",
       "       0.01518152, 0.01188119, 0.01188119, 0.01254125, 0.01452145,\n",
       "       0.01452145, 0.00792079, 0.01056106, 0.00330033, 0.00066007,\n",
       "       0.01452145, 0.01188119, 0.01188119, 0.01452145, 0.00792079,\n",
       "       0.00726073, 0.01386139, 0.01518152, 0.00594059, 0.01518152,\n",
       "       0.01386139, 0.01650165, 0.01518152, 0.01320132, 0.01122112,\n",
       "       0.01386139, 0.01320132, 0.01650165, 0.01320132, 0.01122112,\n",
       "       0.00990099, 0.01188119, 0.01386139, 0.00528053, 0.01122112,\n",
       "       0.00924092, 0.01320132, 0.01056106, 0.01320132, 0.01518152,\n",
       "       0.01188119, 0.01584158, 0.01386139, 0.01254125, 0.01320132,\n",
       "       0.01254125, 0.01650165, 0.01254125, 0.01386139, 0.01452145,\n",
       "       0.01452145, 0.01386139, 0.01188119, 0.01320132, 0.00858086,\n",
       "       0.01188119, 0.00990099, 0.00990099, 0.01452145, 0.01254125,\n",
       "       0.01188119, 0.01188119, 0.01386139, 0.01122112, 0.01188119,\n",
       "       0.01254125, 0.01254125, 0.01518152, 0.01122112, 0.01452145,\n",
       "       0.01188119, 0.01452145, 0.00066007, 0.01320132, 0.01452145,\n",
       "       0.01254125, 0.01056106, 0.00990099, 0.00990099, 0.01320132,\n",
       "       0.01056106, 0.00132013, 0.00924092, 0.01254125, 0.00792079,\n",
       "       0.01122112, 0.01188119, 0.01188119, 0.01122112, 0.01320132,\n",
       "       0.01254125, 0.00924092, 0.01056106, 0.00660066, 0.01188119,\n",
       "       0.01320132, 0.01122112, 0.00990099, 0.00924092, 0.01254125,\n",
       "       0.01320132, 0.01188119, 0.01254125, 0.00990099, 0.01386139])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = (A.T).mean(1)\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177518a7",
   "metadata": {},
   "source": [
    "As we need M as a vector(remeber a vector is a 2-d array in numpy), we need to convert M into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b6f44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_vec = np.matrix(M).T\n",
    "M_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e98c7",
   "metadata": {},
   "source": [
    "The matrix ${B}$ of ${A}^T$ in mean deviation form is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2ce3e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.24752475, -0.24752475, -0.24752475, ...,  0.75247525,\n",
       "          0.75247525,  0.75247525],\n",
       "        [-0.29834983, -0.29834983, -0.29834983, ...,  0.70165017,\n",
       "          0.70165017, -0.29834983],\n",
       "        [-0.32277228,  0.67722772,  0.67722772, ...,  0.67722772,\n",
       "         -0.32277228, -0.32277228],\n",
       "        ...,\n",
       "        [-0.01254125, -0.01254125, -0.01254125, ..., -0.01254125,\n",
       "         -0.01254125, -0.01254125],\n",
       "        [-0.00990099, -0.00990099, -0.00990099, ..., -0.00990099,\n",
       "         -0.00990099, -0.00990099],\n",
       "        [-0.01386139, -0.01386139, -0.01386139, ..., -0.01386139,\n",
       "         -0.01386139, -0.01386139]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A.T - M_vec\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04d76d",
   "metadata": {},
   "source": [
    "To know how many samples we use, we call [shape()](https://www.w3schools.com/python/numpy/numpy_array_shape.asp) on A, as the row numbers are the sample numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74f4fbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515, 520)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e4b2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1515\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de83257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.18637927, 0.03244307, 0.05017199, ..., 0.0048197 , 0.00349216,\n",
       "         0.00779523],\n",
       "        [0.03244307, 0.20947548, 0.05357129, ..., 0.00484237, 0.00298861,\n",
       "         0.00114574],\n",
       "        [0.05017199, 0.05357129, 0.21873471, ..., 0.00321488, 0.00604915,\n",
       "         0.0041095 ],\n",
       "        ...,\n",
       "        [0.0048197 , 0.00484237, 0.00321488, ..., 0.01239215, 0.00053625,\n",
       "         0.00048655],\n",
       "        [0.00349216, 0.00298861, 0.00604915, ..., 0.00053625, 0.00980944,\n",
       "         0.00052317],\n",
       "        [0.00779523, 0.00114574, 0.0041095 , ..., 0.00048655, 0.00052317,\n",
       "         0.01367828]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = (1/(n - 1)) * np.dot(B, B.T)\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a01dd",
   "metadata": {},
   "source": [
    "Therefore, if we want, we could do [PCA(Principal Component Analysis)](https://yunbohua.github.io/pca.html) with our matrix ${A}$. However, as this document emphasizes how to read files and organize the read-in data, delving into PCA would lead us off on a tangent. Therefore, we would skip how to conduct PCA temporarily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8992ccd",
   "metadata": {},
   "source": [
    "## Co-word matrix\n",
    "Then, what is $A^{T}A$? If we ponder over it, we would see that the entries of this matrix record the **numbers** of documents in which two keywords **both** appear. We, therefore, call this matrix **co-word** (or [co-occurence](https://en.wikipedia.org/wiki/Co-occurrence)) matrix. Co-word analysis is one of the fundamental approaches to discovering potential semantic relevancy, analog to [co-citation](https://en.wikipedia.org/wiki/Co-citation) analysis. To learn how to conduct co-citation analysis, please refer to [Co-Citation Count vs Correlation For Influence Network Visualization](https://www.researchgate.net/publication/220586590_Co-Citation_Count_vs_Correlation_for_Influence_Network_Visualization). Please compare formula (1) from the article with the elucidation on $A^{T}A$ given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a74563f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[375., 161., 197., ...,  12.,   9.,  17.],\n",
       "       [161., 452., 227., ...,  13.,   9.,   8.],\n",
       "       [197., 227., 489., ...,  11.,  14.,  13.],\n",
       "       ...,\n",
       "       [ 12.,  13.,  11., ...,  19.,   1.,   1.],\n",
       "       [  9.,   9.,  14., ...,   1.,  15.,   1.],\n",
       "       [ 17.,   8.,  13., ...,   1.,   1.,  21.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A.T, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfff743",
   "metadata": {},
   "source": [
    "## Documents similarity\n",
    "Besides the covariance matrix and co-word matrix mentioned above, there is another critical method to compute the correlation between two documents -- [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). \n",
    "<br><br>\n",
    "What is amazing about cosine similarity is that the likelihood that two documents are related is manifested as an angle. It **\" gives a useful measure of how similar two documents are likely to be, in terms of their subject matter, and independently of the length of the documents.\"**\n",
    "\n",
    "Unfortunately, there isn't a standalone function that performs cosine-similarity computation. Thus, if we want to derive cosine similarity for two documents or a whole collection of documents, we have to resort to the procedure from [create-cosine-similarity-matrix-numpy](https://stackoverflow.com/questions/41905029/create-cosine-similarity-matrix-numpy). To summarize,\n",
    "1. **compute the numerator (using the document matrix ${A}^T$ from above)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaa695ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0., 36.,  2., ...,  3.,  3.,  5.],\n",
       "       [ 0.,  2.,  6., ...,  1.,  0.,  1.],\n",
       "       ...,\n",
       "       [ 0.,  3.,  1., ..., 13.,  4.,  2.],\n",
       "       [ 1.,  3.,  0., ...,  4., 35.,  4.],\n",
       "       [ 0.,  5.,  1., ...,  2.,  4., 28.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = A.T.T@A.T\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a63a49",
   "metadata": {},
   "source": [
    "\n",
    "2. **norm = (A.T * A.T).sum(0, keepdims=True) ** .5**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Recall that * is done element by element. About how sum() works can be found [here](https://stackoverflow.com/questions/39441517/in-numpy-sum-there-is-parameter-called-keepdims-what-does-it-do)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf0c7a8",
   "metadata": {},
   "source": [
    "Basically, we call sum(0, keepdims=True) to sum up **all the row vectors** from ${A^T}$ \\* ${A^T}$  so that the resultant vector has the square length of each document as entries.\n",
    "<br>\n",
    "<br>\n",
    "\\*\\* .5 literally means taking the square root of (A.T * A.T).sum(0, keepdims=True). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90948e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.        , 6.        , 2.44948974, ..., 3.60555128, 5.91607978,\n",
       "        5.29150262]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = (A.T * A.T).sum(0, keepdims=True) ** .5\n",
    "norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcc0db",
   "metadata": {},
   "source": [
    "3. **d / norm / norm.T**\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f40ee94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.08451543,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.13608276, ..., 0.13867505, 0.08451543,\n",
       "        0.1574852 ],\n",
       "       [0.        , 0.13608276, 1.        , ..., 0.1132277 , 0.        ,\n",
       "        0.07715167],\n",
       "       ...,\n",
       "       [0.        , 0.13867505, 0.1132277 , ..., 1.        , 0.18752289,\n",
       "        0.10482848],\n",
       "       [0.08451543, 0.08451543, 0.        , ..., 0.18752289, 1.        ,\n",
       "        0.12777531],\n",
       "       [0.        , 0.1574852 , 0.07715167, ..., 0.10482848, 0.12777531,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine = d/norm/norm.T\n",
    "cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11688cb",
   "metadata": {},
   "source": [
    "4. **distance： 1 - d / norm / norm.T(optional)**\n",
    "<br>\n",
    "\n",
    "This step calculates the so-called [cosine distances](https://en.wikipedia.org/wiki/Cosine_similarity#Definition), which can be understood as the opposite of similarity. The result is an adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "788c700c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00,  9.15484575e-01,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  0.00000000e+00,  8.63917237e-01, ...,\n",
       "         8.61324951e-01,  9.15484575e-01,  8.42514803e-01],\n",
       "       [ 1.00000000e+00,  8.63917237e-01, -2.22044605e-16, ...,\n",
       "         8.86772297e-01,  1.00000000e+00,  9.22848325e-01],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  8.61324951e-01,  8.86772297e-01, ...,\n",
       "        -2.22044605e-16,  8.12477108e-01,  8.95171516e-01],\n",
       "       [ 9.15484575e-01,  9.15484575e-01,  1.00000000e+00, ...,\n",
       "         8.12477108e-01,  0.00000000e+00,  8.72224687e-01],\n",
       "       [ 1.00000000e+00,  8.42514803e-01,  9.22848325e-01, ...,\n",
       "         8.95171516e-01,  8.72224687e-01,  2.22044605e-16]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_matrix = 1 - d / norm / norm.T\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f6608",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "I am planning to\n",
    "1. visualize the adjacency matrix as a graph and\n",
    "2. utilize PCA to reduce the selection of keywords."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
